> 原课程网址：https://cs231n.github.io/linear-classify/
> 翻译：Colopen  
> 校对：Colopen

# Linear Classification

在上一节中，我们介绍了图像分类问题，即从一组固定类别标签中选择一个分配给图像。此外，我们还介绍了k-Nearest Neighbor(kNN)分类器，该分类器通过将测试图像与训练集中的图像进行比较来进行分类。正如我们所见，kNN有着相当多的缺陷：

1. 分类器必须记住并存储所有的训练数据，以便未来与测试数据进行比较。空间效率十分低下，因为数据集的大小可能很容易打到千兆字节。  
2. 对一张测试图片进行分类的计算开销十分大，因为它需要与整个训练集中的图片一一进行比较。

**Overview.** 我们现在要实现一个更强大的图像分类器，并最终将自然地拓展到整个神经网络和卷积神经网络。该方法有两个主要组成部分：一个可以将原始数据映射到类别分数的**评分函数(score function)**，以及一个量化预测分类标签的得分与真实标签之间一致性的**损失函数(loss function)**。接下来我们会把该问题转化为优化问题，在这个优化问题中，我们将更新评分函数的参数值，以便能够最小化损失函数。

## Parameterized mapping from images to label scores

该方法的第一个重要组成部分是定义评分函数，评分函数用来将图片的像素值映射到各个分类标签的得分上（得分高低代表图像属于该类别的可能性高低）。我们将用一个具体例子来实现这个方法。正如之前一样，我们先假设有一个包含很多图片的训练集 $x_i\in R^D$，且每张图片都有一个分类标签 $y_i$，其中 $i=1 \cdots N,y_i\in 1 \cdots K$。这表示我们有N个图片样例（每个样例的维度为D）和K个独立的分类标签。例如CIFAR-10的训练集，有 N=50,000 张图片，每张图片有 D = 32 x 32 x 3 = 3072个像素，和K=10个独立的分类标签（狗，猫，车等等）。我们现在将定义一个把原始图像的像素值映射到各个分类标签得分的评分函数 $f: R^D \mapsto R^K$。

**Linear classifier.** 在这个模型中，我们将从最简单的函数开始，线性映射：

$$
f(x_i, W, b) = Wx_i + b
$$

在上述方程中，$x_i$ 是将图像 i 像素拉成 [D x 1] 形状而形成的列向量，而矩阵 $W_{K \times D}$ 和向量 $b_{K\times1}$ 则是函数的**参数(parameters)**。在CIFAR-10数据集中，$x_i$包含第i张图片的所有像素信息，且这些信息被拉成一个 [3072 x 1] 的列向量。$W$ 大小为 [10 x 3072]，$b$ 的大小为 [10 x 1]。所以，这3072个数字（原始像素值）输入函数后，就会输出10个数字（分类标签得分）。参数 $W$ 常被称作 **权重(weights)**，$b$ 常被称作 **偏置向量(bias vector)**，因为他不和原始数据 $x_i$ 产生联系，但会影响输出的数值。然而，你经常会听到人们混用 *权重* 和 *参数* 这两个术语。

有几件事需要注意：

- 首先要注意，矩阵乘法 $x_i$ 有效地并行评估10个不同的分类器（每个分类器针对一个分类），其中$W$ 每一行是一个分类器  
- 还要注意，我们认为输入数据 $(x_i,y_i)$ 是给定的且不可改变的，但我们可以调整参数 $W, b$ 的取值。我们的目标是通过设置这些参数，使得计算出的分类分数与训练集中对应的真实标签相匹配。我们接下来会更加详细的探讨这个过程是如何完成的，但是从直觉上来讲，我们希望正确分类的分数应该远高于不正确的分数。  
- 这个方法的一个优势是训练集仅仅用于学习参数 $W,b$，一旦学习完毕，我们就会丢弃整个训练集，只保留学习好的参数。这是因为一个测试图片可以简单地输入该函数，然后根据该函数输出的分类分值直接进行分类。  
- 最后要注意，对一张测试图像的分类仅仅只涉及到一个简单的矩阵乘法和矩阵加法，这比起拿一张测试图片与整个训练集的图片进行比较要快的多。

> 预告：卷积神经网络也会像上述一样，将图像的像素映射成分类分值。不一样的是，卷积神经网络的映射(f) 远比这复杂，而且还包含更多的参数。

## Interpreting a linear classifier

线性分类器对于一张图片的各个分类标签得分的计算法则是：计算这张图片的3个颜色通道中所有像素值的加权和。根据我们为这些权重设置的值，函数就具有喜欢或不喜欢（取决于每个权重的符号）图像中某些位置某些颜色的能力。例如，在一张图中，如果有许多蓝色在画面的两侧（可能对应于水），那么这张图很大概率属于"船"类。所以你会期望"船"分类器在其蓝色通道权重中会有很多正权重（蓝色的存在会增加船的分数），而红/绿通道权重中有很多负权重（红色/绿色的存在会降低船的分数）。

![](https://cs231n.github.io/assets/imagemap.jpg)



## Loss function
### Multiclass Support Vector Machine loss
## Practical Considerations
## Softmax classifier
## SVM vs. Softmax
## Interactive web demo
## Summary
## Further Reading